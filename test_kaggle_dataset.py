"""
Kaggleæ•°æ®é›†æµ‹è¯•è„šæœ¬
éªŒè¯æ•°æ®åŠ è½½å’Œæ¨¡å‹åˆ›å»ºæ˜¯å¦æ­£å¸¸å·¥ä½œ
é€‚é…æ•°æ®é›†ç»“æ„: /kaggle/input/dataset/ID_1 åˆ° ID_31
"""

import os
import torch
import torch.nn as nn
from torchvision import transforms
from pathlib import Path
import numpy as np
from PIL import Image
import json
import argparse
from collections import defaultdict

from dalle2_pytorch import Unet, Decoder, OpenClipAdapter
from dalle2_pytorch.micro_doppler_dalle2 import (
    UserConditionedPriorNetwork, 
    UserConditionedDiffusionPrior, 
    MicroDopplerDALLE2
)
from dalle2_pytorch.dataloaders import create_micro_doppler_dataloader, MicroDopplerDataset


def analyze_kaggle_dataset(data_root='/kaggle/input/dataset'):
    """åˆ†æKaggleæ•°æ®é›†ç»“æ„å’Œç»Ÿè®¡ä¿¡æ¯"""
    
    print("ğŸ” Analyzing Kaggle dataset structure...")
    data_path = Path(data_root)
    
    if not data_path.exists():
        print(f"âŒ Dataset path {data_path} does not exist!")
        return False
    
    # ç»Ÿè®¡ä¿¡æ¯
    user_stats = {}
    total_images = 0
    image_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']
    
    # æ£€æŸ¥æ¯ä¸ªç”¨æˆ·æ–‡ä»¶å¤¹
    for i in range(1, 32):  # ID_1 to ID_31
        folder_name = f"ID_{i}"
        folder_path = data_path / folder_name
        
        if folder_path.exists() and folder_path.is_dir():
            # ç»Ÿè®¡å›¾åƒæ–‡ä»¶
            image_files = []
            for ext in image_extensions:
                image_files.extend(list(folder_path.glob(f'*{ext}')))
                image_files.extend(list(folder_path.glob(f'*{ext.upper()}')))
            
            user_stats[i] = {
                'folder': folder_name,
                'path': str(folder_path),
                'image_count': len(image_files),
                'image_files': [f.name for f in image_files[:5]]  # åªæ˜¾ç¤ºå‰5ä¸ªæ–‡ä»¶å
            }
            total_images += len(image_files)
            
            print(f"âœ… {folder_name}: {len(image_files)} images")
            if len(image_files) > 0:
                print(f"   ğŸ“ Sample files: {', '.join(user_stats[i]['image_files'])}")
        else:
            print(f"âŒ Missing: {folder_name}")
            user_stats[i] = {'folder': folder_name, 'image_count': 0}
    
    # æ‰“å°ç»Ÿè®¡æ‘˜è¦
    print(f"\nğŸ“Š Dataset Summary:")
    print(f"   Total users: {len([u for u in user_stats.values() if u['image_count'] > 0])}/31")
    print(f"   Total images: {total_images}")
    print(f"   Average images per user: {total_images/31:.1f}")
    
    # æ£€æŸ¥å›¾åƒå°ºå¯¸ (é‡‡æ ·å‡ å¼ å›¾åƒ)
    print(f"\nğŸ–¼ï¸  Checking image properties...")
    sample_images = []
    for i in range(1, min(6, 32)):  # æ£€æŸ¥å‰5ä¸ªç”¨æˆ·
        folder_path = data_path / f"ID_{i}"
        if folder_path.exists():
            for ext in image_extensions:
                files = list(folder_path.glob(f'*{ext}'))
                if files:
                    sample_images.append(files[0])
                    break
    
    if sample_images:
        sizes = []
        for img_path in sample_images[:3]:  # åªæ£€æŸ¥å‰3å¼ 
            try:
                with Image.open(img_path) as img:
                    sizes.append(img.size)
                    print(f"   ğŸ“ {img_path.parent.name}/{img_path.name}: {img.size}, mode: {img.mode}")
            except Exception as e:
                print(f"   âŒ Error reading {img_path}: {e}")
        
        if sizes:
            unique_sizes = list(set(sizes))
            print(f"   ğŸ“ Unique image sizes: {unique_sizes}")
    
    return user_stats


def test_dataloader(data_root='/kaggle/input/dataset', num_users=31):
    """æµ‹è¯•å¾®å¤šæ™®å‹’æ•°æ®åŠ è½½å™¨"""
    
    print("\nğŸ§ª Testing MicroDopplerDataset...")
    
    try:
        # æµ‹è¯•æ•°æ®é›†åˆ›å»º
        dataset = MicroDopplerDataset(
            data_root=data_root,
            num_users=num_users,
            image_size=256
        )
        
        print(f"âœ… Dataset loaded: {len(dataset)} samples")
        
        if len(dataset) == 0:
            print("âŒ No samples found in dataset!")
            return None
        
        # æµ‹è¯•æ•°æ®åŠ è½½
        sample = dataset[0]
        print(f"âœ… Sample keys: {sample.keys()}")
        print(f"   ğŸ“ Image shape: {sample['image'].shape}")
        print(f"   ğŸ‘¤ User ID: {sample['user_id']}")
        print(f"   ğŸ“ Original folder: {sample.get('original_folder', 'N/A')}")
        
        # æµ‹è¯•æ•°æ®åŠ è½½å™¨
        dataloader = create_micro_doppler_dataloader(
            data_root=data_root,
            batch_size=4,
            num_workers=0,  # åœ¨Kaggleä¸­ä½¿ç”¨0é¿å…å¤šè¿›ç¨‹é—®é¢˜
            num_users=num_users,
            shuffle=True
        )
        
        batch = next(iter(dataloader))
        print(f"âœ… Batch image shape: {batch['image'].shape}")
        print(f"   ğŸ‘¥ Batch user_ids: {batch['user_id']}")
        
        # æµ‹è¯•ç”¨æˆ·åˆ†å¸ƒ
        user_dist = dataset.get_user_distribution()
        print(f"âœ… User distribution: {dict(sorted(user_dist.items()))}")
        
        return dataloader
        
    except Exception as e:
        print(f"âŒ Dataloader test failed: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_models(num_users=31):
    """æµ‹è¯•æ¨¡å‹åˆ›å»ºå’Œå‰å‘ä¼ æ’­"""
    
    print("\nğŸ§ª Testing model creation...")
    
    try:
        # æµ‹è¯•UserConditionedPriorNetwork
        print("ğŸ—ï¸  Creating UserConditionedPriorNetwork...")
        prior_network = UserConditionedPriorNetwork(
            dim=512,
            num_users=num_users,
            user_embed_dim=64,
            depth=2,  # å‡å°æ·±åº¦ç”¨äºæµ‹è¯•
            dim_head=64,
            heads=4,
            num_timesteps=1000,  # æ ‡å‡†æ‰©æ•£æ­¥æ•° (è®­ç»ƒç”¨1000æ­¥)
            rotary_emb=True
        )
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size = 4
        image_embed = torch.randn(batch_size, 512)
        user_ids = torch.randint(0, num_users, (batch_size,))
        timesteps = torch.randint(0, 1000, (batch_size,)).long()  # åŒ¹é…æ¨¡å‹çš„timestepsèŒƒå›´
        
        pred = prior_network(image_embed, timesteps, user_ids=user_ids)
        print(f"âœ… Prior network output shape: {pred.shape}")
        
        # æµ‹è¯•UserConditionedDiffusionPrior
        print("ğŸ—ï¸  Creating UserConditionedDiffusionPrior...")
        clip = OpenClipAdapter('ViT-B/32')
        
        diffusion_prior = UserConditionedDiffusionPrior(
            net=prior_network,
            clip=clip,
            timesteps=1000,        # è®­ç»ƒæ—¶ä½¿ç”¨1000æ­¥
            sample_timesteps=64,   # æ¨ç†æ—¶ä½¿ç”¨64æ­¥ (DDIMåŠ é€Ÿ)
            num_users=num_users
        )
        
        # æµ‹è¯•è®­ç»ƒå‰å‘ä¼ æ’­
        images = torch.randn(batch_size, 3, 256, 256)
        with torch.no_grad():
            image_embeds = clip.embed_image(images).image_embed
        
        loss = diffusion_prior(image_embeds, user_ids=user_ids)
        print(f"âœ… Prior training loss: {loss.item():.4f}")
        
        # æµ‹è¯•é‡‡æ ·
        with torch.no_grad():
            sampled_embeds = diffusion_prior.sample(
                user_ids=user_ids[:2],
                num_samples_per_batch=1,
                cond_scale=1.0
            )
        print(f"âœ… Sampled embeddings shape: {sampled_embeds.shape}")
        
        # æµ‹è¯•Decoder
        print("ğŸ—ï¸  Creating Decoder...")
        unet = Unet(
            dim=64,  # å‡å°ç»´åº¦ç”¨äºæµ‹è¯•
            image_embed_dim=512,
            cond_dim=128,
            channels=3,
            dim_mults=(1, 2, 4),
            cond_on_image_embeds=True,
            cond_on_text_encodings=False
        )
        
        decoder = Decoder(
            unet=unet,
            clip=clip,
            image_sizes=(256,),
            timesteps=1000  # æ ‡å‡†æ‰©æ•£æ­¥æ•°
        )
        
        # æµ‹è¯•è§£ç å™¨è®­ç»ƒ
        decoder_loss = decoder(images)
        print(f"âœ… Decoder training loss: {decoder_loss.item():.4f}")
        
        # æµ‹è¯•è§£ç å™¨é‡‡æ ·
        with torch.no_grad():
            generated_images = decoder.sample(image_embed=sampled_embeds)
        print(f"âœ… Generated images shape: {generated_images.shape}")
        
        print("ğŸ‰ All model tests passed!")
        return True
        
    except Exception as e:
        print(f"âŒ Model test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_training_compatibility(dataloader):
    """æµ‹è¯•è®­ç»ƒå…¼å®¹æ€§"""
    
    print("\nğŸ§ª Testing training compatibility...")
    
    try:
        # åˆ›å»ºç®€åŒ–æ¨¡å‹ç”¨äºæµ‹è¯•
        clip = OpenClipAdapter('ViT-B/32')
        
        prior_network = UserConditionedPriorNetwork(
            dim=256,  # å‡å°ç»´åº¦
            num_users=31,
            user_embed_dim=32,
            depth=2,
            dim_head=32,
            heads=4,
            num_timesteps=1000,  # æ ‡å‡†æ‰©æ•£æ­¥æ•°
            rotary_emb=True
        )
        
        diffusion_prior = UserConditionedDiffusionPrior(
            net=prior_network,
            clip=clip,
            timesteps=1000,      # è®­ç»ƒæ—¶ä½¿ç”¨1000æ­¥
            sample_timesteps=64, # æ¨ç†æ—¶ä½¿ç”¨64æ­¥
            num_users=31
        )
        
        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
        batch = next(iter(dataloader))
        images = batch['image']
        user_ids = batch['user_id']
        
        print(f"ğŸ“Š Batch info:")
        print(f"   Images shape: {images.shape}")
        print(f"   User IDs: {user_ids}")
        print(f"   Unique users in batch: {torch.unique(user_ids).tolist()}")
        
        # æµ‹è¯•å…ˆéªŒè®­ç»ƒæ­¥éª¤
        with torch.no_grad():
            image_embeds = diffusion_prior.clip.embed_image(images).image_embed
        
        prior_loss = diffusion_prior(image_embeds, user_ids=user_ids)
        print(f"âœ… Prior loss with real data: {prior_loss.item():.4f}")
        
        print("ğŸ‰ Training compatibility test passed!")
        return True
        
    except Exception as e:
        print(f"âŒ Training compatibility test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    parser = argparse.ArgumentParser(description='Test Kaggle Micro-Doppler Dataset')
    parser.add_argument('--data_root', type=str, default='/kaggle/input/dataset',
                        help='Path to Kaggle dataset')
    parser.add_argument('--num_users', type=int, default=31,
                        help='Number of users (ID_1 to ID_31)')
    
    args = parser.parse_args()
    
    print("ğŸš€ Starting Kaggle dataset tests...")
    print(f"ğŸ“‚ Data root: {args.data_root}")
    
    try:
        # 1. åˆ†ææ•°æ®é›†
        user_stats = analyze_kaggle_dataset(args.data_root)
        if not user_stats:
            return 1
        
        # 2. æµ‹è¯•æ•°æ®åŠ è½½å™¨
        dataloader = test_dataloader(args.data_root, args.num_users)
        if dataloader is None:
            return 1
        
        # 3. æµ‹è¯•æ¨¡å‹
        if not test_models(args.num_users):
            return 1
        
        # 4. æµ‹è¯•è®­ç»ƒå…¼å®¹æ€§
        if not test_training_compatibility(dataloader):
            return 1
        
        print("\nğŸ‰ All tests passed! Ready for training on Kaggle.")
        print("\nğŸ“‹ Next steps:")
        print("1. Run decoder training: python train_kaggle_decoder.py --use_vqgan")
        print("2. Run prior training: python train_kaggle_prior.py")
        print("3. Generate images with trained models")
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    exit(main())
