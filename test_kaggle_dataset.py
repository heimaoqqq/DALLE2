"""
Kaggleæ•°æ®é›†æµ‹è¯•è„šæœ¬
éªŒè¯æ•°æ®åŠ è½½å’Œæ¨¡å‹åˆ›å»ºæ˜¯å¦æ­£å¸¸å·¥ä½œ
é€‚é…æ•°æ®é›†ç»“æ„: /kaggle/input/dataset/ID_1 åˆ° ID_31
"""

import os
import torch
import torch.nn as nn
from torchvision import transforms
from pathlib import Path
import numpy as np
from PIL import Image
import json
import argparse
from collections import defaultdict

# è®¾ç½®è®¾å¤‡
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸ”§ Test device: {device}")
if torch.cuda.is_available():
    print(f"ğŸ”§ GPU count: {torch.cuda.device_count()}")
    print(f"ğŸ”§ GPU name: {torch.cuda.get_device_name(0)}")
    print(f"ğŸ”§ GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    # è®¾ç½®å†…å­˜ä¼˜åŒ–
    torch.backends.cudnn.benchmark = True
    torch.backends.cuda.matmul.allow_tf32 = True
    print("ğŸ”§ GPU optimizations enabled")
else:
    print("âš ï¸  CUDA not available, using CPU")

def print_gpu_memory():
    """æ‰“å°GPUå†…å­˜ä½¿ç”¨æƒ…å†µ"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1e9
        reserved = torch.cuda.memory_reserved() / 1e9
        print(f"ğŸ“Š GPU Memory - Allocated: {allocated:.1f}GB, Reserved: {reserved:.1f}GB")

from dalle2_pytorch import Unet, Decoder, OpenClipAdapter
from dalle2_pytorch.micro_doppler_dalle2 import (
    UserConditionedPriorNetwork, 
    UserConditionedDiffusionPrior, 
    MicroDopplerDALLE2
)
from dalle2_pytorch.dataloaders import create_micro_doppler_dataloader, MicroDopplerDataset


def analyze_kaggle_dataset(data_root='/kaggle/input/dataset'):
    """åˆ†æKaggleæ•°æ®é›†ç»“æ„å’Œç»Ÿè®¡ä¿¡æ¯"""
    
    print("ğŸ” Analyzing Kaggle dataset structure...")
    data_path = Path(data_root)
    
    if not data_path.exists():
        print(f"âŒ Dataset path {data_path} does not exist!")
        return False
    
    # ç»Ÿè®¡ä¿¡æ¯
    user_stats = {}
    total_images = 0
    image_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']
    
    # æ£€æŸ¥æ¯ä¸ªç”¨æˆ·æ–‡ä»¶å¤¹
    for i in range(1, 32):  # ID_1 to ID_31
        folder_name = f"ID_{i}"
        folder_path = data_path / folder_name
        
        if folder_path.exists() and folder_path.is_dir():
            # ç»Ÿè®¡å›¾åƒæ–‡ä»¶
            image_files = []
            for ext in image_extensions:
                image_files.extend(list(folder_path.glob(f'*{ext}')))
                image_files.extend(list(folder_path.glob(f'*{ext.upper()}')))
            
            user_stats[i] = {
                'folder': folder_name,
                'path': str(folder_path),
                'image_count': len(image_files),
                'image_files': [f.name for f in image_files[:5]]  # åªæ˜¾ç¤ºå‰5ä¸ªæ–‡ä»¶å
            }
            total_images += len(image_files)
            
            print(f"âœ… {folder_name}: {len(image_files)} images")
            if len(image_files) > 0:
                print(f"   ğŸ“ Sample files: {', '.join(user_stats[i]['image_files'])}")
        else:
            print(f"âŒ Missing: {folder_name}")
            user_stats[i] = {'folder': folder_name, 'image_count': 0}
    
    # æ‰“å°ç»Ÿè®¡æ‘˜è¦
    print(f"\nğŸ“Š Dataset Summary:")
    print(f"   Total users: {len([u for u in user_stats.values() if u['image_count'] > 0])}/31")
    print(f"   Total images: {total_images}")
    print(f"   Average images per user: {total_images/31:.1f}")
    
    # æ£€æŸ¥å›¾åƒå°ºå¯¸ (é‡‡æ ·å‡ å¼ å›¾åƒ)
    print(f"\nğŸ–¼ï¸  Checking image properties...")
    sample_images = []
    for i in range(1, min(6, 32)):  # æ£€æŸ¥å‰5ä¸ªç”¨æˆ·
        folder_path = data_path / f"ID_{i}"
        if folder_path.exists():
            for ext in image_extensions:
                files = list(folder_path.glob(f'*{ext}'))
                if files:
                    sample_images.append(files[0])
                    break
    
    if sample_images:
        sizes = []
        for img_path in sample_images[:3]:  # åªæ£€æŸ¥å‰3å¼ 
            try:
                with Image.open(img_path) as img:
                    sizes.append(img.size)
                    print(f"   ğŸ“ {img_path.parent.name}/{img_path.name}: {img.size}, mode: {img.mode}")
            except Exception as e:
                print(f"   âŒ Error reading {img_path}: {e}")
        
        if sizes:
            unique_sizes = list(set(sizes))
            print(f"   ğŸ“ Unique image sizes: {unique_sizes}")
    
    return user_stats


def test_dataloader(data_root='/kaggle/input/dataset', num_users=31):
    """æµ‹è¯•å¾®å¤šæ™®å‹’æ•°æ®åŠ è½½å™¨"""
    
    print("\nğŸ§ª Testing MicroDopplerDataset...")
    
    try:
        # æµ‹è¯•æ•°æ®é›†åˆ›å»º
        dataset = MicroDopplerDataset(
            data_root=data_root,
            num_users=num_users,
            image_size=256
        )
        
        print(f"âœ… Dataset loaded: {len(dataset)} samples")
        
        if len(dataset) == 0:
            print("âŒ No samples found in dataset!")
            return None
        
        # æµ‹è¯•æ•°æ®åŠ è½½
        sample = dataset[0]
        print(f"âœ… Sample keys: {sample.keys()}")
        print(f"   ğŸ“ Image shape: {sample['image'].shape}")
        print(f"   ğŸ‘¤ User ID: {sample['user_id']}")
        print(f"   ğŸ“ Original folder: {sample.get('original_folder', 'N/A')}")
        
        # æµ‹è¯•æ•°æ®åŠ è½½å™¨
        dataloader = create_micro_doppler_dataloader(
            data_root=data_root,
            batch_size=4,
            num_workers=0,  # åœ¨Kaggleä¸­ä½¿ç”¨0é¿å…å¤šè¿›ç¨‹é—®é¢˜
            num_users=num_users,
            shuffle=True
        )
        
        batch = next(iter(dataloader))
        print(f"âœ… Batch image shape: {batch['image'].shape}")
        print(f"   ğŸ‘¥ Batch user_ids: {batch['user_id']}")
        
        # æµ‹è¯•ç”¨æˆ·åˆ†å¸ƒ
        user_dist = dataset.get_user_distribution()
        print(f"âœ… User distribution: {dict(sorted(user_dist.items()))}")
        
        return dataloader
        
    except Exception as e:
        print(f"âŒ Dataloader test failed: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_models(num_users=31):
    """æµ‹è¯•æ¨¡å‹åˆ›å»ºå’Œå‰å‘ä¼ æ’­"""
    
    print("\nğŸ§ª Testing model creation...")
    
    try:
        # æµ‹è¯•UserConditionedPriorNetwork
        print("ğŸ—ï¸  Creating UserConditionedPriorNetwork...")
        prior_network = UserConditionedPriorNetwork(
            dim=512,
            num_users=num_users,
            user_embed_dim=64,
            depth=2,  # å‡å°æ·±åº¦ç”¨äºæµ‹è¯•
            dim_head=64,
            heads=4,
            num_timesteps=1000,  # æ ‡å‡†æ‰©æ•£æ­¥æ•° (è®­ç»ƒç”¨1000æ­¥)
            rotary_emb=True
        ).to(device)  # ç§»åŠ¨åˆ°GPU

        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size = 4
        image_embed = torch.randn(batch_size, 512, device=device)  # åœ¨GPUä¸Šåˆ›å»º
        user_ids = torch.randint(0, num_users, (batch_size,), device=device)  # åœ¨GPUä¸Šåˆ›å»º
        timesteps = torch.randint(0, 1000, (batch_size,), device=device).long()  # åœ¨GPUä¸Šåˆ›å»º
        
        pred = prior_network(image_embed, timesteps, user_ids=user_ids)
        print(f"âœ… Prior network output shape: {pred.shape}")
        print_gpu_memory()

        # æµ‹è¯•UserConditionedDiffusionPrior
        print("ğŸ—ï¸  Creating UserConditionedDiffusionPrior...")
        clip = OpenClipAdapter('ViT-B/32')
        
        diffusion_prior = UserConditionedDiffusionPrior(
            net=prior_network,
            clip=clip,
            timesteps=1000,        # è®­ç»ƒæ—¶ä½¿ç”¨1000æ­¥
            sample_timesteps=64,   # æ¨ç†æ—¶ä½¿ç”¨64æ­¥ (DDIMåŠ é€Ÿ)
            num_users=num_users
        ).to(device)  # ç§»åŠ¨åˆ°GPU

        # æµ‹è¯•è®­ç»ƒå‰å‘ä¼ æ’­
        images = torch.randn(batch_size, 3, 256, 256, device=device)  # åœ¨GPUä¸Šåˆ›å»º
        with torch.no_grad():
            image_embeds = clip.embed_image(images).image_embed
        
        loss = diffusion_prior(image_embeds, user_ids=user_ids)
        print(f"âœ… Prior training loss: {loss.item():.4f}")
        
        # æµ‹è¯•é‡‡æ ·
        with torch.no_grad():
            sampled_embeds = diffusion_prior.sample(
                user_ids=user_ids[:2],  # å·²ç»åœ¨GPUä¸Š
                num_samples_per_batch=1,
                cond_scale=1.0
            )
        print(f"âœ… Sampled embeddings shape: {sampled_embeds.shape}")

        # æ¸…ç†GPUå†…å­˜
        torch.cuda.empty_cache()
        print(f"ğŸ§¹ GPU memory cleared")

        # æµ‹è¯•Decoder (æå°é…ç½®ç”¨äºå†…å­˜æµ‹è¯•)
        print("ğŸ—ï¸  Creating Decoder...")
        unet = Unet(
            dim=32,  # æå°ç»´åº¦ç”¨äºæµ‹è¯•
            image_embed_dim=512,
            cond_dim=64,  # å‡å°æ¡ä»¶ç»´åº¦
            channels=3,
            dim_mults=(1, 2),  # å‡å°‘å±‚æ•°
            cond_on_image_embeds=True,
            cond_on_text_encodings=False,
            memory_efficient=True  # å¯ç”¨å†…å­˜ä¼˜åŒ–
        )
        
        decoder = Decoder(
            unet=unet,
            clip=clip,
            image_sizes=(256,),  # ä¿æŒ256x256ä»¥æ»¡è¶³CLIPè¦æ±‚
            timesteps=100,  # å‡å°‘timestepsç”¨äºæµ‹è¯•
            sample_timesteps=10  # æå°‘çš„é‡‡æ ·æ­¥æ•°
        ).to(device)  # ç§»åŠ¨åˆ°GPU

        # ä½¿ç”¨æ­£ç¡®å°ºå¯¸çš„æµ‹è¯•å›¾åƒ (CLIPéœ€è¦è‡³å°‘224x224)
        test_images = torch.randn(1, 3, 256, 256, device=device)  # åªç”¨1å¼ å›¾åƒå‡å°‘å†…å­˜

        # æµ‹è¯•è§£ç å™¨è®­ç»ƒ
        decoder_loss = decoder(test_images)
        print(f"âœ… Decoder training loss: {decoder_loss.item():.4f}")

        # æ¸…ç†å†…å­˜
        torch.cuda.empty_cache()

        # è·³è¿‡è§£ç å™¨é‡‡æ ·æµ‹è¯•ä»¥èŠ‚çœå†…å­˜
        print("â­ï¸  Skipping decoder sampling test to save GPU memory")
        print("âœ… Generated images shape: [Skipped for memory]")
        
        print("ğŸ‰ All model tests passed!")
        return True
        
    except Exception as e:
        print(f"âŒ Model test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_training_compatibility(dataloader):
    """æµ‹è¯•è®­ç»ƒå…¼å®¹æ€§"""
    
    print("\nğŸ§ª Testing training compatibility...")
    
    try:
        # åˆ›å»ºç®€åŒ–æ¨¡å‹ç”¨äºæµ‹è¯•
        clip = OpenClipAdapter('ViT-B/32')
        
        prior_network = UserConditionedPriorNetwork(
            dim=512,  # åŒ¹é…CLIP embeddingç»´åº¦
            num_users=31,
            user_embed_dim=64,  # å¢åŠ ç”¨æˆ·embeddingç»´åº¦
            depth=2,
            dim_head=64,  # åŒ¹é…ä¸»æµ‹è¯•
            heads=4,
            num_timesteps=1000,  # æ ‡å‡†æ‰©æ•£æ­¥æ•°
            rotary_emb=True
        ).to(device)  # ç§»åŠ¨åˆ°GPU

        diffusion_prior = UserConditionedDiffusionPrior(
            net=prior_network,
            clip=clip,
            timesteps=1000,      # è®­ç»ƒæ—¶ä½¿ç”¨1000æ­¥
            sample_timesteps=64, # æ¨ç†æ—¶ä½¿ç”¨64æ­¥
            num_users=31
        ).to(device)  # ç§»åŠ¨åˆ°GPU
        
        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
        batch = next(iter(dataloader))
        images = batch['image'].to(device)  # ç§»åŠ¨åˆ°GPU
        user_ids = batch['user_id'].to(device)  # ç§»åŠ¨åˆ°GPU

        print(f"ğŸ“Š Batch info:")
        print(f"   Images shape: {images.shape}")
        print(f"   User IDs: {user_ids}")
        print(f"   Unique users in batch: {torch.unique(user_ids).tolist()}")

        # æµ‹è¯•å…ˆéªŒè®­ç»ƒæ­¥éª¤
        with torch.no_grad():
            image_embeds = diffusion_prior.clip.embed_image(images).image_embed

        prior_loss = diffusion_prior(image_embeds, user_ids=user_ids)
        print(f"âœ… Prior loss with real data: {prior_loss.item():.4f}")
        
        print("ğŸ‰ Training compatibility test passed!")
        return True
        
    except Exception as e:
        print(f"âŒ Training compatibility test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    parser = argparse.ArgumentParser(description='Test Kaggle Micro-Doppler Dataset')
    parser.add_argument('--data_root', type=str, default='/kaggle/input/dataset',
                        help='Path to Kaggle dataset')
    parser.add_argument('--num_users', type=int, default=31,
                        help='Number of users (ID_1 to ID_31)')
    
    args = parser.parse_args()
    
    print("ğŸš€ Starting Kaggle dataset tests...")
    print(f"ğŸ“‚ Data root: {args.data_root}")
    
    try:
        # 1. åˆ†ææ•°æ®é›†
        user_stats = analyze_kaggle_dataset(args.data_root)
        if not user_stats:
            return 1
        
        # 2. æµ‹è¯•æ•°æ®åŠ è½½å™¨
        dataloader = test_dataloader(args.data_root, args.num_users)
        if dataloader is None:
            return 1
        
        # 3. æµ‹è¯•æ¨¡å‹
        if not test_models(args.num_users):
            return 1
        
        # 4. æµ‹è¯•è®­ç»ƒå…¼å®¹æ€§
        if not test_training_compatibility(dataloader):
            return 1
        
        print("\nğŸ‰ All tests passed! Ready for training on Kaggle.")
        print("\nğŸ“‹ Next steps:")
        print("1. Run decoder training: python train_kaggle_decoder.py --use_vqgan")
        print("2. Run prior training: python train_kaggle_prior.py")
        print("3. Generate images with trained models")
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    exit(main())
