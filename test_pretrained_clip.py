#!/usr/bin/env python3
"""
æµ‹è¯•ä½¿ç”¨é¢„è®­ç»ƒCLIPçš„ç®€å•DALLE2é…ç½®
"""

import torch
import torch.nn as nn
from dalle2_pytorch import DALLE2, DiffusionPriorNetwork, DiffusionPrior, Unet, Decoder, OpenAIClipAdapter
import argparse
from pathlib import Path

def create_simple_dalle2():
    """åˆ›å»ºä½¿ç”¨é¢„è®­ç»ƒCLIPçš„ç®€å•DALLE2æ¨¡å‹"""
    print("ğŸ”§ Creating DALLE2 with pretrained OpenAI CLIP...")
    
    # ä½¿ç”¨é¢„è®­ç»ƒçš„OpenAI CLIP
    clip = OpenAIClipAdapter('ViT-B/32')
    print("âœ… Pretrained CLIP loaded")
    
    # åˆ›å»ºç®€å•çš„Priorç½‘ç»œ
    prior_network = DiffusionPriorNetwork(
        dim=512,
        depth=2,  # å‡å°‘æ·±åº¦
        dim_head=64,
        heads=4   # å‡å°‘å¤´æ•°
    )
    
    diffusion_prior = DiffusionPrior(
        net=prior_network,
        clip=clip,
        timesteps=100,  # å‡å°‘æ—¶é—´æ­¥
        cond_drop_prob=0.2
    )
    print("âœ… Prior network created")
    
    # åˆ›å»ºç®€å•çš„U-Net
    unet = Unet(
        dim=64,  # å‡å°‘ç»´åº¦
        image_embed_dim=512,
        cond_dim=128,
        channels=3,
        dim_mults=(1, 2),  # åªç”¨ä¸¤å±‚
        cond_on_image_embeds=True,
        cond_on_text_encodings=False
    )
    
    decoder = Decoder(
        unet=unet,
        clip=clip,
        image_sizes=(224,),  # å•ä¸€å°ºå¯¸
        timesteps=100,       # å‡å°‘æ—¶é—´æ­¥
        sample_timesteps=20, # å¿«é€Ÿé‡‡æ ·
        image_cond_drop_prob=0.1,
        text_cond_drop_prob=0.5
    )
    print("âœ… Decoder created")
    
    # ç»„åˆæˆå®Œæ•´çš„DALLE2
    dalle2 = DALLE2(
        prior=diffusion_prior,
        decoder=decoder
    )
    print("âœ… DALLE2 model created successfully")
    
    return dalle2

def test_memory_and_forward():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨å’Œå‰å‘ä¼ æ’­"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”§ Using device: {device}")
    
    if torch.cuda.is_available():
        print(f"ğŸ”§ GPU memory: {torch.cuda.get_device_properties(0).total_memory/1024**3:.1f}GB")
        torch.cuda.empty_cache()
        print(f"ğŸ”§ Initial GPU memory: {torch.cuda.memory_allocated()/1024**3:.2f}GB")
    
    try:
        # åˆ›å»ºæ¨¡å‹
        dalle2 = create_simple_dalle2()
        dalle2 = dalle2.to(device)
        
        if torch.cuda.is_available():
            print(f"ğŸ”§ GPU memory after model: {torch.cuda.memory_allocated()/1024**3:.2f}GB")
        
        # æµ‹è¯•æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ
        print("ğŸ¨ Testing text-to-image generation...")
        
        with torch.no_grad():
            # ç®€å•çš„æ–‡æœ¬è¾“å…¥
            text = ["a red car", "a blue house"]
            
            # ç”Ÿæˆå›¾åƒ
            images = dalle2(
                text,
                cond_scale=2.0,
                return_pil_images=False
            )
            
            print(f"âœ… Generated images shape: {images.shape}")
            print(f"âœ… Images range: [{images.min().item():.3f}, {images.max().item():.3f}]")
            
            if torch.cuda.is_available():
                print(f"ğŸ”§ GPU memory after generation: {torch.cuda.memory_allocated()/1024**3:.2f}GB")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        if torch.cuda.is_available():
            print(f"ğŸ”§ GPU memory at error: {torch.cuda.memory_allocated()/1024**3:.2f}GB")
        return False

def test_with_your_data():
    """æµ‹è¯•ä½¿ç”¨æ‚¨çš„å¾®å¤šæ™®å‹’æ•°æ®"""
    print("ğŸ”¬ Testing with micro-Doppler-like data...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    try:
        dalle2 = create_simple_dalle2()
        dalle2 = dalle2.to(device)
        
        # æ¨¡æ‹Ÿæ‚¨çš„æ•°æ®ï¼šç”¨æˆ·IDåˆ°å›¾åƒçš„æ˜ å°„
        # è¿™é‡Œæˆ‘ä»¬ç”¨ç®€å•çš„æ–‡æœ¬æè¿°ä»£æ›¿ç”¨æˆ·ID
        user_descriptions = [
            "user walking pattern",
            "user running pattern", 
            "user standing pattern"
        ]
        
        print("ğŸ¯ Generating micro-Doppler patterns...")
        
        with torch.no_grad():
            images = dalle2(
                user_descriptions,
                cond_scale=1.5,
                return_pil_images=False
            )
            
            print(f"âœ… Generated {len(user_descriptions)} patterns")
            print(f"âœ… Pattern shape: {images.shape}")
            
            # æ£€æŸ¥ç”Ÿæˆçš„å›¾åƒæ˜¯å¦æœ‰å˜åŒ–
            for i, desc in enumerate(user_descriptions):
                img = images[i]
                print(f"ğŸ”§ {desc}: range [{img.min().item():.3f}, {img.max().item():.3f}], std {img.std().item():.3f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error in micro-Doppler test: {e}")
        return False

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--test_basic', action='store_true', help='Test basic functionality')
    parser.add_argument('--test_micro_doppler', action='store_true', help='Test micro-Doppler generation')
    args = parser.parse_args()
    
    print("ğŸš€ Testing DALLE2 with pretrained CLIP...")
    
    if args.test_basic or not any([args.test_basic, args.test_micro_doppler]):
        print("\n=== Basic Functionality Test ===")
        success = test_memory_and_forward()
        if not success:
            print("âŒ Basic test failed")
            return
    
    if args.test_micro_doppler:
        print("\n=== Micro-Doppler Test ===")
        success = test_with_your_data()
        if not success:
            print("âŒ Micro-Doppler test failed")
            return
    
    print("\nâœ… All tests passed! You can now adapt this for your specific use case.")
    print("ğŸ’¡ Next steps:")
    print("   1. Replace text descriptions with your user ID embeddings")
    print("   2. Fine-tune on your micro-Doppler dataset")
    print("   3. Adjust model size based on your memory constraints")

if __name__ == "__main__":
    main()
