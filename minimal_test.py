#!/usr/bin/env python3
"""
æç®€æ‰©æ•£æ¨¡å‹æµ‹è¯• - ç”¨äºè¯Šæ–­å†…å­˜é—®é¢˜
"""

import torch
import torch.nn as nn
from dalle2_pytorch import OpenClipAdapter
from dalle2_pytorch.dalle2_pytorch import Unet, Decoder
import argparse

def create_minimal_unet():
    """åˆ›å»ºæœ€å°çš„U-Neté…ç½®"""
    return Unet(
        dim=16,  # æå°çš„åŸºç¡€ç»´åº¦
        image_embed_dim=512,  # CLIP embeddingç»´åº¦
        cond_dim=64,  # æå°çš„æ¡ä»¶ç»´åº¦
        channels=3,
        dim_mults=(1,),  # åªæœ‰ä¸€å±‚
        cond_on_image_embeds=True,
        cond_on_text_encodings=False,
        # ç¦ç”¨æ‰€æœ‰å¯èƒ½æ¶ˆè€—å†…å­˜çš„åŠŸèƒ½
        memory_efficient=True,
        init_dim=None,
        init_conv_kernel_size=7,
        resnet_groups=1,  # æœ€å°ç»„æ•°
        attn_dim_head=8,  # æå°çš„æ³¨æ„åŠ›å¤´
        attn_heads=1,  # å•ä¸ªæ³¨æ„åŠ›å¤´
        ff_mult=1,  # æœ€å°çš„å‰é¦ˆå€æ•°
        layer_attns=False,  # ç¦ç”¨å±‚æ³¨æ„åŠ›
        layer_cross_attns=False,  # ç¦ç”¨äº¤å‰æ³¨æ„åŠ›
    )

def test_memory_usage():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
    print("ğŸ”§ Testing minimal configuration...")
    
    # åˆ›å»ºCLIP
    clip = OpenClipAdapter('ViT-B/32')
    print(f"âœ… CLIP created successfully")
    
    # åˆ›å»ºæœ€å°U-Net
    try:
        unet = create_minimal_unet()
        print(f"âœ… Minimal U-Net created successfully")
        print(f"ğŸ”§ U-Net parameters: {sum(p.numel() for p in unet.parameters()):,}")
    except Exception as e:
        print(f"âŒ U-Net creation failed: {e}")
        return False
    
    # åˆ›å»ºè§£ç å™¨
    try:
        decoder = Decoder(
            unet=unet,
            clip=clip,
            vae=None,  # åƒç´ ç©ºé—´
            image_sizes=(224,),
            timesteps=100,  # æå°‘çš„æ—¶é—´æ­¥
            sample_timesteps=10,
            image_cond_drop_prob=0.1,
            text_cond_drop_prob=0.0,
            beta_schedule='cosine',
            predict_x_start=True,
            predict_v=False,
            learned_variance=False
        )
        print(f"âœ… Decoder created successfully")
    except Exception as e:
        print(f"âŒ Decoder creation failed: {e}")
        return False
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    try:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        decoder = decoder.to(device)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 1
        test_images = torch.randn(batch_size, 3, 224, 224, device=device)
        
        print(f"ğŸ”§ Testing forward pass with batch_size={batch_size}")
        print(f"ğŸ”§ GPU memory before: {torch.cuda.memory_allocated()/1024**3:.2f}GB")
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            loss = decoder(test_images)
            print(f"âœ… Forward pass successful, loss: {loss.item():.4f}")
            print(f"ğŸ”§ GPU memory after: {torch.cuda.memory_allocated()/1024**3:.2f}GB")
            
    except Exception as e:
        print(f"âŒ Forward pass failed: {e}")
        print(f"ğŸ”§ GPU memory at failure: {torch.cuda.memory_allocated()/1024**3:.2f}GB")
        return False
    
    return True

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--test_forward', action='store_true', help='Test forward pass')
    args = parser.parse_args()
    
    print("ğŸš€ Starting minimal memory test...")
    
    if torch.cuda.is_available():
        print(f"ğŸ”§ GPU: {torch.cuda.get_device_name()}")
        print(f"ğŸ”§ GPU memory: {torch.cuda.get_device_properties(0).total_memory/1024**3:.1f}GB")
    else:
        print("âŒ No GPU available")
        return
    
    success = test_memory_usage()
    
    if success:
        print("âœ… Minimal configuration works!")
        if args.test_forward:
            print("ğŸ¯ You can try scaling up the configuration gradually")
    else:
        print("âŒ Even minimal configuration failed")
        print("ğŸ”§ This suggests a fundamental issue with the environment or library")

if __name__ == "__main__":
    main()
